# Q-Learning-on-Blackjack
Teaching an Agent to play Blackjack using Q-Learning. The code is explained in the [Monte_Carlo.ipynb](https://github.com/ShivankYadav/Q-Learning-on-Blackjack/blob/master/Monte_Carlo.ipynb). You guys are welcome to imporve the hyperparameters or even the algorithm for better performance. I have also provided a [presentation](https://github.com/ShivankYadav/Q-Learning-on-Blackjack/blob/master/MinorProject.pptx) and a [report](https://github.com/ShivankYadav/Q-Learning-on-Blackjack/blob/master/Report.docx) to explain **Monte Carlo Control Algorithms**.

## Environment Description
https://github.com/openai/gym/blob/master/gym/envs/toy_text/blackjack.py

## Install requirements
Simply execute this on your shell: ```$pip install -r ```[requirements.txt](https://github.com/ShivankYadav/Q-Learning-on-Blackjack/blob/master/requirements.txt)
For visualizations, I was not able to install basemap using pip. So I used 
```conda install -c anaconda basemap```
## Algorithm used:
!["Algorithm_image"](https://github.com/ShivankYadav/Q-Learning-on-Blackjack/blob/master/images/algos.png)
